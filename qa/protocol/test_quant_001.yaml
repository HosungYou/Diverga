# Diverga QA Protocol v3.0
# Scenario QUANT-001: Experimental Design with Power Analysis (English)
#
# Purpose: Test quantitative research agents with experimental design,
# power analysis, and statistical methodology selection.
#
# Complexity: MEDIUM (4-6 turns expected)
# Language: English
# CLI: Codex

scenario_id: QUANT-001
name: "Experimental Design with Power Analysis"
version: "3.0"
paradigm: quantitative
complexity_level: MEDIUM

# VERIFICATION HUDDLE
verification_huddle:
  enabled: true
  markers:
    - type: NO_SIMULATION_MARKERS
    - type: RESPONSE_LENGTH_VARIANCE
    - type: TIMESTAMP_VARIANCE
    - type: CONTEXT_AWARENESS
    - type: UNIQUE_SESSION_ID
    - type: DYNAMIC_CONTENT

agents_involved:
  - A1-ResearchQuestionRefiner
  - A2-TheoreticalFrameworkArchitect
  - C1-QuantitativeDesignConsultant
  - D1-SamplingStrategyAdvisor
  - E1-QuantitativeAnalysisGuide

language: "English"
expected_turns: 4-6
expected_technical_questions: 1
expected_methodological_challenges: 1

checkpoints_expected:
  - id: CP_PARADIGM_SELECTION
    level: RED
    mandatory_halt: true

  - id: CP_RESEARCH_DESIGN
    level: RED
    mandatory_halt: true

  - id: CP_SAMPLE_SIZE
    level: ORANGE
    mandatory_halt: false

  - id: CP_METHODOLOGY_APPROVAL
    level: RED
    mandatory_halt: true

conversation_flow:
  - turn: 1
    user_type: INITIAL_REQUEST
    user: |
      I want to study the effect of gamification on employee engagement
      in corporate training programs. I'm planning a randomized controlled
      trial comparing gamified vs traditional e-learning. I need to know
      how many participants I need and what statistical tests to use.

    expected_behavior:
      paradigm_detection: quantitative
      keyword_triggers:
        - "effect"
        - "randomized controlled trial"
        - "participants"
        - "statistical tests"
      checkpoint: CP_PARADIGM_SELECTION
      language: English
      halt: true
      vs_options_min: 2

  - turn: 2
    user_type: TECHNICAL_FOLLOW_UP
    user: |
      For the power analysis, I expect a medium effect size (d = 0.5).
      I want 80% power with alpha = 0.05. How many participants per group
      do I need? Also, should I use independent samples t-test or ANCOVA?

    expected_behavior:
      provides_calculation: true
      discusses:
        - "sample size calculation"
        - "G*Power"
        - "effect size"
        - "statistical power"
      contrasts_approaches:
        - "t-test vs ANCOVA"
        - "covariates"
      checkpoint: CP_SAMPLE_SIZE
      language: English

  - turn: 3
    user_type: METHODOLOGICAL_CHALLENGE
    user: |
      What about attrition? If I expect 20% dropout, how should I adjust
      my sample size? And how do I handle missing data - listwise deletion
      or multiple imputation?

    expected_behavior:
      honest_assessment: true
      discusses:
        - "attrition adjustment"
        - "missing data mechanisms"
        - "MCAR, MAR, MNAR"
        - "multiple imputation"
      provides_recommendation: true
      language: English

  - turn: 4
    user_type: APPROVAL
    user: |
      This is helpful. I'll recruit 80 per group (160 total) to account
      for attrition. I'll use ANCOVA controlling for baseline engagement
      and handle missing data with multiple imputation. Please summarize
      the design and give me next steps.

    expected_behavior:
      final_approval: true
      generates_summary: true
      suggests_next_steps:
        - "Develop engagement measure"
        - "Design gamification intervention"
        - "Pre-register on OSF"
        - "Obtain IRB approval"
      checkpoint: CP_METHODOLOGY_APPROVAL
      language: English

validation_rules:
  checkpoint_compliance:
    target: 100%
    red_checkpoints_must_halt: true

  language_consistency:
    input_language: English
    response_language: English
    must_match: true

  quantitative_accuracy:
    must_calculate_sample_size: true
    must_discuss_power: true
    must_mention_effect_size: true

  verification_huddle:
    no_dry_run_markers: true
    no_simulation_markers: true
    response_variance_required: true

metrics_targets:
  total_turns: ">=4"
  technical_questions_handled: ">=1"
  checkpoint_compliance: "100%"
  language_consistency: "100%"
  verification_huddle_pass: true
